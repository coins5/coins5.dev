---
title: "Cleaning Data Without Losing Your Mind (Pandas Edition)"
pubDate: 2025-05-12
description: "Learn how to clean messy data using Pandas. We'll fix missing values, rename columns, convert data types, and prepare our dataset for analysis."
author: "coins5"
image:
  url: "/src/assets/images/posts_cover/loguru_handle_concurrency.png"
  alt: "Cleaning Data Without Losing Your Mind (Pandas Edition)"
tags: ["python", "pandas", "analytics"]
nextPost: "series/pandas/filter-select-slice-with-pandas"
serie: "learn-pandas"
seriesPartNumber: 3
---

# Cleaning Data Without Losing Your Mind (Pandas Edition) ğŸ§¼

Messy data is the rule, not the exception.  
Before any serious analysis or machine learning, we need to make sure the data is **clean, consistent, and usable**.

In this post, weâ€™ll go over how to:

âœ… Fix missing values  
âœ… Rename columns  
âœ… Convert data types  
âœ… Clean strings and categories

Letâ€™s get to work.

---

## ğŸ§¹ Step 1: Detect missing data

Weâ€™ll use the same dataset from before (`prices_sample.csv`).

```python
import pandas as pd

df = pd.read_csv("prices_sample.csv")

# Check for missing values
print(df.isnull().sum())
```

Even if this dataset is clean, itâ€™s good practice to check. In real-world data, missing prices, categories, or names are super common.

---

## ğŸ’Š Step 2: Fill or remove missing data

You have a few options here:

- **Drop rows** with missing values:

```python
df_clean = df.dropna()
```

- **Fill missing values** with a default (e.g. 0, "Unknown", or a mean):

```python
df["price"] = df["price"].fillna(0)
df["brand"] = df["brand"].fillna("Unknown")
```

- **Fill with column average** (for numeric columns):

```python
df["price"] = df["price"].fillna(df["price"].mean())
```

---

## âœï¸ Step 3: Rename columns

Make column names consistent, lowercase, and readable:

```python
# Rename with a dictionary
df.rename(columns={"product_name": "name", "in_stock": "available"}, inplace=True)

# Or make all lowercase
df.columns = [col.lower() for col in df.columns]
```

Why? Because you donâ€™t want to type `Product Name` 100 times, or deal with spaces.

---

## ğŸ”¢ Step 4: Convert data types

Letâ€™s make sure each column has the right type:

```python
# Convert price to float
df["price"] = df["price"].astype(float)

# Convert in_stock to boolean
df["available"] = df["available"].astype(bool)
```

For dates (in future entries):

```python
df["date"] = pd.to_datetime(df["date"])
```

---

## ğŸ”¤ Step 5: Clean string columns

Sometimes, text columns come with extra whitespace, wrong casing, or typos.

```python
# Strip whitespace and lowercase everything
df["category"] = df["category"].str.strip().str.lower()

# Standardize brand names
df["brand"] = df["brand"].replace({"Laive ": "Laive", "laive": "Laive"})
```

You can also remove symbols or accents using regular expressions (str.replace()), or normalize text with unidecode if needed.

---

## âœ… Final check

Now that weâ€™ve cleaned up, letâ€™s check how things look:

```python
print(df.info())
print(df.head())
```

---

## ğŸ§  Key Takeaways

- Clean data is the foundation of any good analysis
- Learn to love `.isnull()`, `.fillna()`, and `.astype()`
- Standardizing strings and column names saves a lot of bugs later

## ğŸ“Œ Whatâ€™s next?

Next up in the series:
â¡ï¸ Filtering, selecting, and slicing your data like a ninja ğŸ¥·

Weâ€™ll explore `.loc`, `.iloc`, boolean indexing, and more to really dig into the rows and columns that matter.

See you in Part 4!
